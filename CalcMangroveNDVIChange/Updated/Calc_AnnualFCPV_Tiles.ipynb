{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.features\n",
    "import datacube\n",
    "import numpy\n",
    "from datacube.storage import masking\n",
    "import xarray\n",
    "import argparse\n",
    "import os.path\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import pandas\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "\n",
    "def xarray_to_cfnetcdf(data_xarray, output_nc_file, variable_name, crs):\n",
    "    # Data Cube friendly dataset, copy booleans to int8 as bool is not supported\n",
    "    dcf_ds = data_xarray.astype('int8', copy=False).to_dataset(name = variable_name)\n",
    "    # set a valid crs object, DC relies upon the python object so a WKT representation of CRS will fail\n",
    "    dcf_ds.attrs['crs'] = crs\n",
    "    # Set units for year coordinate\n",
    "    dcf_ds.coords['time'].attrs['units'] = 'date and time of observations'\n",
    "    # Set units for data variable    \n",
    "    dcf_ds.data_vars[variable_name].attrs['units'] = 1\n",
    "    # write dataset out using datacube storage method - this is an unfortunate nessicity and we should expose a\n",
    "    # function like this in a nicer way\n",
    "    write_dataset_to_netcdf(dcf_ds, output_nc_file)\n",
    "\n",
    "def pq_fuser(dest, src):\n",
    "    valid_bit = 8\n",
    "    valid_val = (1 << valid_bit)\n",
    "\n",
    "    no_data_dest_mask = ~(dest & valid_val).astype(bool)\n",
    "    numpy.copyto(dest, src, where=no_data_dest_mask)\n",
    "\n",
    "    both_data_mask = (valid_val & dest & src).astype(bool)\n",
    "    numpy.copyto(dest, src & dest, where=both_data_mask)\n",
    "\n",
    "def calcMangFCPVMangPxlFromCube(tileNCFile, tileNCAMCFile, tileAFile, minLat, maxLat, minLon, maxLon, mangShpExt, pv_thresh):\n",
    "\n",
    "    dc = datacube.Datacube(app='CalcAnnualMangroveExtent')\n",
    "    \n",
    "    #Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "    bands_of_interest = ['PV']\n",
    "    \n",
    "    #Define sensors of interest\n",
    "    sensors = ['ls8', 'ls7', 'ls5']\n",
    "    \n",
    "    #define temporal range\n",
    "    start_of_epoch = '1987-01-01'\n",
    "    # latest observation\n",
    "    end_of_epoch = '2016-12-31'\n",
    "    \n",
    "    query = {'time': (start_of_epoch, end_of_epoch),}\n",
    "    query['x'] = (minLon, maxLon)\n",
    "    query['y'] = (maxLat, minLat)\n",
    "    query['crs'] = 'EPSG:4326'\n",
    "    \n",
    "    #Define which pixel quality artefacts you want removed from the results\n",
    "    mask_components = {'cloud_acca':          'no_cloud',\n",
    "                       'cloud_shadow_acca' :  'no_cloud_shadow',\n",
    "                       'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "                       'cloud_fmask' :        'no_cloud',\n",
    "                       'blue_saturated' :     False,\n",
    "                       'green_saturated' :    False,\n",
    "                       'red_saturated' :      False,\n",
    "                       'nir_saturated' :      False,\n",
    "                       'swir1_saturated' :    False,\n",
    "                       'swir2_saturated' :    False,\n",
    "                       'contiguous' :         True }\n",
    "    \n",
    "    print(\"Read pixel image data into memory.\")\n",
    "    sensor_clean = {}\n",
    "    for sensor in sensors:\n",
    "        print(sensor)\n",
    "        #Load the FC and corresponding PQ\n",
    "        sensor_fc = dc.load(product=sensor+'_fc_albers', group_by='solar_day', measurements=bands_of_interest, **query)\n",
    "        if bool(sensor_fc):\n",
    "            sensor_pq = dc.load(product=sensor+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)\n",
    "            # Get the projection info\n",
    "            crs = sensor_fc.crs\n",
    "            affine = sensor_fc.affine\n",
    "            # Apply the PQ masks to the FC\n",
    "            cloud_free = masking.make_mask(sensor_pq, **mask_components)\n",
    "            good_data = cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "            sensor_fc = sensor_fc.where(good_data)\n",
    "            sensor_clean[sensor] = sensor_fc\n",
    "    \n",
    "    if bool(sensor_clean):\n",
    "        print(\"Merge data from different sensors.\")\n",
    "        fc_clean = xarray.concat(sensor_clean.values(), dim='time')\n",
    "        time_sorted = fc_clean.time.argsort()\n",
    "        fc_clean = fc_clean.isel(time=time_sorted)\n",
    "        \n",
    "        print(\"Create Composite\")\n",
    "        annual = fc_clean.resample('A', dim='time', how='median', keep_attrs=True)\n",
    "        \n",
    "        print(\"Rasterise the GMW extent map for the area of interest.\")\n",
    "        # Define pixel size and NoData value of new raster\n",
    "        xres = affine[0]\n",
    "        yres = affine[4]\n",
    "        noDataVal = -9999\n",
    "        \n",
    "        # Set the geotransform properties\n",
    "        xcoord = annual.coords['x'].min()\n",
    "        ycoord = annual.coords['y'].max()\n",
    "        geotransform = (xcoord - (xres*0.5), xres, 0, ycoord + (yres*0.5), 0, yres)\n",
    "        \n",
    "        # Open the data source and read in the extent\n",
    "        source_ds = ogr.Open(mangShpExt)\n",
    "        source_layer = source_ds.GetLayer()\n",
    "        source_srs = source_layer.GetSpatialRef()\n",
    "        vx_min, vx_max, vy_min, vy_max = source_layer.GetExtent() # This is extent of Australia\n",
    "        \n",
    "        # Create the destination extent\n",
    "        yt,xt = annual.PV.isel(time=1).shape\n",
    "        \n",
    "        # Set up 'in-memory' gdal image to rasterise the shapefile too\n",
    "        target_ds = gdal.GetDriverByName('MEM').Create('', xt, yt, gdal.GDT_Byte)\n",
    "        target_ds.SetGeoTransform(geotransform)\n",
    "        albers = osr.SpatialReference()\n",
    "        albers.ImportFromEPSG(3577)\n",
    "        target_ds.SetProjection(albers.ExportToWkt())\n",
    "        band = target_ds.GetRasterBand(1)\n",
    "        band.SetNoDataValue(noDataVal)\n",
    "        \n",
    "        # Rasterise\n",
    "        gdal.RasterizeLayer(target_ds, [1], source_layer, burn_values=[1])\n",
    "        \n",
    "        # Read as array the GMW mask\n",
    "        gmwMaskArr = band.ReadAsArray()\n",
    "        \n",
    "        \n",
    "        print(\"Apply the GMW Mask to the FCPV values\")\n",
    "        mangroveannual = (annual.PV.where(gmwMaskArr == 1))\n",
    "        \n",
    "        print(\"Apply thresholds to FCPV to find total mangrove mask.\")\n",
    "        mangroveAreaPxlC = mangroveannual>pv_thresh\n",
    "        \n",
    "        print(\"Calculate the number of pixels within the mangrove mask and write to CSV file.\")\n",
    "        numMangPxls = numpy.sum(mangroveAreaPxlC.data)\n",
    "\n",
    "        for datetimeVal in annual.time:\n",
    "            yearVal=datetimeVal['time.year'].data\n",
    "\n",
    "            numMangPxls = numpy.sum(mangroveAreaPxlC.sel(time=datetimeVal).data)\n",
    "\n",
    "            pxlCountSeries = pandas.Series([numMangPxls], index=['MangPxls'])\n",
    "            tileAFileOut = tileAFile+'_'+str(yearVal)+'.csv'\n",
    "            pxlCountSeries.to_csv(tileAFileOut)\n",
    "            \n",
    "            tileNCAMCFileOut = tileNCAMCFile+'_'+str(yearVal)+'.nc'\n",
    "            tileNCFileOut = tileNCFile+'_'+str(yearVal)+'.nc'\n",
    "\n",
    "            xarray_to_cfnetcdf(mangroveAreaPxlC.sel(time=datetimeVal), tileNCAMCFileOut, 'PV'+str(yearVal), crs)           \n",
    "            xarray_to_cfnetcdf(mangroveannual.sel(time=datetimeVal), tileNCFileOut, 'PV'+str(yearVal), crs)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir =  os.path.expanduser('~/mangrove/')\n",
    "\n",
    "#output files\n",
    "tileNCFile = working_dir + 'pv_1695_14115_0_pv'\n",
    "tileNCAMCFile = working_dir + 'pv_1695_14115_0_mangmask'\n",
    "tileAFile = working_dir + 'pv_1695_14115_0_pxlcounts'\n",
    "#This notebook expects you to have access to this file\n",
    "gmwMangExtShp = working_dir + 'GMW_Australia_MangroveExtent2010_AlbersEA_shp.shp'\n",
    "minlat = -17.0 \n",
    "maxlat = -16.9 \n",
    "minlon = 141.1\n",
    "maxlon = 141.2\n",
    "pv_thresh = 30\n",
    "calcMangFCPVMangPxlFromCube(tileNCFile, tileNCAMCFile, tileAFile, minlat, maxlat, minlon, maxlon, gmwMangExtShp, pv_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
