{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc_AnnualFCPV_Tiles.py\n",
    "\n",
    "import datacube\n",
    "import numpy\n",
    "from datacube.storage import masking\n",
    "import xarray\n",
    "import argparse\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import pandas\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "\n",
    "\n",
    "def xarray_to_cfnetcdf(data_xarray, output_nc_file, variable_name, crs, year, nodata_val=-1):\n",
    "    data_xarray = data_xarray.fillna(nodata_val)\n",
    "    # Data Cube friendly dataset, copy booleans to int8 as bool is not supported\n",
    "    dcf_ds = data_xarray.astype('int8', copy=False).to_dataset(name = variable_name)\n",
    "    # set a valid crs object, DC relies upon the python object so a WKT representation of CRS will fail\n",
    "    dcf_ds.attrs['crs'] = crs\n",
    "    # Set units for year coordinate\n",
    "    dcf_ds.coords['time'].attrs['units'] = 'year of annual composite'    \n",
    "    # Set units for data variable\n",
    "    dcf_ds.data_vars[variable_name].attrs['units'] = 1\n",
    "    dcf_ds.data_vars[variable_name].attrs['nodata'] = nodata_val\n",
    "    # write dataset out using datacube storage method - this is an unfortunate nessicity and we should expose a\n",
    "    # function like this in a nicer way\n",
    "    write_dataset_to_netcdf(dcf_ds, output_nc_file)\n",
    "\n",
    "\n",
    "def pq_fuser(dest, src):\n",
    "    valid_bit = 8\n",
    "    valid_val = (1 << valid_bit)\n",
    "\n",
    "    no_data_dest_mask = ~(dest & valid_val).astype(bool)\n",
    "    numpy.copyto(dest, src, where=no_data_dest_mask)\n",
    "\n",
    "    both_data_mask = (valid_val & dest & src).astype(bool)\n",
    "    numpy.copyto(dest, src & dest, where=both_data_mask)\n",
    "\n",
    "\n",
    "def calc_mang_fcpv(threshold, mangrove, pixel_count, min_lat, max_lat, min_lon, max_lon, mangrove_ext, pv_threshold):\n",
    "\n",
    "    dc = datacube.Datacube(app='CalcAnnualMangroveExtent')\n",
    "    \n",
    "    # Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "    bands_of_interest = ['PV']\n",
    "    \n",
    "    # Define sensors of interest\n",
    "    sensors = ['ls8', 'ls7', 'ls5']\n",
    "    \n",
    "    # define temporal range\n",
    "    start_of_epoch = '1987-01-01'\n",
    "    # latest observation\n",
    "    end_of_epoch = '2016-12-31'\n",
    "    \n",
    "    query = dict(time=(start_of_epoch, end_of_epoch))\n",
    "    query['x'] = (min_lon, max_lon)\n",
    "    query['y'] = (max_lat, min_lat)\n",
    "    query['crs'] = 'EPSG:4326'\n",
    "    \n",
    "    # Define which pixel quality artefacts you want removed from the results\n",
    "    mask_components = {'cloud_acca': 'no_cloud',\n",
    "                       'cloud_shadow_acca': 'no_cloud_shadow',\n",
    "                       'cloud_shadow_fmask': 'no_cloud_shadow',\n",
    "                       'cloud_fmask': 'no_cloud',\n",
    "                       'blue_saturated': False,\n",
    "                       'green_saturated': False,\n",
    "                       'red_saturated': False,\n",
    "                       'nir_saturated': False,\n",
    "                       'swir1_saturated': False,\n",
    "                       'swir2_saturated': False,\n",
    "                       'contiguous': True}\n",
    "    \n",
    "    print(\"Read pixel image data into memory.\")\n",
    "    sensor_clean = {}\n",
    "    affine = None\n",
    "    for sensor in sensors:\n",
    "        print(sensor)\n",
    "        # Load the FC and corresponding PQ\n",
    "        sensor_fc = dc.load(product=sensor+'_fc_albers', group_by='solar_day', measurements=bands_of_interest, **query)\n",
    "        if bool(sensor_fc):\n",
    "            sensor_pq = dc.load(product=sensor+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)\n",
    "            # Get the projection info\n",
    "            crs = sensor_fc.crs\n",
    "            affine = sensor_fc.affine\n",
    "            # Apply the PQ masks to the FC\n",
    "            cloud_free = masking.make_mask(sensor_pq, **mask_components)\n",
    "            good_data = cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "            sensor_fc = sensor_fc.where(good_data)\n",
    "            sensor_clean[sensor] = sensor_fc\n",
    "    \n",
    "    if bool(sensor_clean):\n",
    "        print(\"Merge data from different sensors.\")\n",
    "        fc_clean = xarray.concat(sensor_clean.values(), dim='time')\n",
    "        time_sorted = fc_clean.time.argsort()\n",
    "        fc_clean = fc_clean.isel(time=time_sorted)\n",
    "        \n",
    "        print(\"Create Composite\")\n",
    "        annual = fc_clean.resample('A', dim='time', how='median', keep_attrs=True)\n",
    "        \n",
    "        print(\"Rasterise the GMW extent map for the area of interest.\")\n",
    "        # Define pixel size and NoData value of new raster\n",
    "        xres = affine[0]\n",
    "        yres = affine[4]\n",
    "        no_data_value = -9999\n",
    "        \n",
    "        # Set the geotransform properties\n",
    "        xcoord = annual.coords['x'].min()\n",
    "        ycoord = annual.coords['y'].max()\n",
    "        geotransform = (xcoord - (xres*0.5), xres, 0, ycoord + (yres*0.5), 0, yres)\n",
    "        \n",
    "        # Open the data source and read in the extent\n",
    "        source_ds = ogr.Open(mangrove_ext)\n",
    "        source_layer = source_ds.GetLayer()\n",
    "        #  source_srs = source_layer.GetSpatialRef()\n",
    "        #  vx_min, vx_max, vy_min, vy_max = source_layer.GetExtent()  # This is extent of Australia\n",
    "        \n",
    "        # Create the destination extent\n",
    "        yt, xt = annual.PV.isel(time=1).shape\n",
    "        \n",
    "        # Set up 'in-memory' gdal image to rasterise the shapefile too\n",
    "        target_ds = gdal.GetDriverByName('MEM').Create('', xt, yt, gdal.GDT_Byte)\n",
    "        target_ds.SetGeoTransform(geotransform)\n",
    "        albers = osr.SpatialReference()\n",
    "        albers.ImportFromEPSG(3577)\n",
    "        target_ds.SetProjection(albers.ExportToWkt())\n",
    "        band = target_ds.GetRasterBand(1)\n",
    "        band.SetNoDataValue(no_data_value)\n",
    "        \n",
    "        # Rasterise\n",
    "        gdal.RasterizeLayer(target_ds, [1], source_layer, burn_values=[1])\n",
    "        \n",
    "        # Read as array the GMW mask\n",
    "        gmw_mask_array = band.ReadAsArray()\n",
    "\n",
    "        print(\"Apply the GMW Mask to the FCPV values\")\n",
    "        mangrove_annual = (annual.PV.where(gmw_mask_array == 1))\n",
    "        \n",
    "        print(\"Apply thresholds to FCPV to find total mangrove mask.\")\n",
    "        mangrove_pv_threshold = mangrove_annual.where(mangrove_annual>pv_threshold)\n",
    "        \n",
    "        print(\"Calculate the number of pixels within the mangrove mask and write to CSV file.\")\n",
    "\n",
    "        for datetimeVal in annual.time:\n",
    "            year_value=datetimeVal['time.year'].data\n",
    "\n",
    "            num_mang_pxls = numpy.sum(mangrove_pv_threshold.sel(time=datetimeVal).data)\n",
    "\n",
    "            pixel_count_series = pandas.Series([num_mang_pxls], index=['MangPxls'])\n",
    "            pixel_count_out = pixel_count+'_'+str(year_value)+'.csv'\n",
    "            pixel_count_series.to_csv(pixel_count_out)\n",
    "\n",
    "            threshold_out = threshold+'_'+str(year_value)+'.nc'\n",
    "            mangrove_out = mangrove+'_'+str(year_value)+'.nc'\n",
    "\n",
    "            xarray_to_cfnetcdf(mangrove_pv_threshold.sel(time=datetimeVal), threshold_out, 'PV', crs, str(year_value))\n",
    "            xarray_to_cfnetcdf(mangrove_annual.sel(time=datetimeVal), mangrove_out, 'PV', crs, str(year_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir =  os.path.expanduser('~/mangrove/')\n",
    "\n",
    "#output files\n",
    "threshold = working_dir + 'pv_1695_14115_0_pv'\n",
    "mangrove = working_dir + 'pv_1695_14115_0_mangmask'\n",
    "pixel_count = working_dir + 'pv_1695_14115_0_pxlcounts'\n",
    "#This notebook expects you to have access to this file\n",
    "mangrove_ext = working_dir + 'GMW_Australia_MangroveExtent2010_AlbersEA_shp.shp'\n",
    "min_lat = -17.0 \n",
    "max_lat = -16.9 \n",
    "min_lon = 141.1\n",
    "max_lon = 141.2\n",
    "pv_threshold = 30\n",
    "calc_mang_fcpv(threshold, mangrove, pixel_count, min_lat, max_lat, min_lon, max_lon, mangrove_ext, pv_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
